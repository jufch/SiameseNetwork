{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into pairs of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Siamese Networks, it is necessary to build pairs of images for the input (to give to the model). In this Notebbok, we will split the dataset in 3 files like it has been done for the training of the CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.getcwd() + \"/Split_Tanker_Bulk_Container_frugal_vv/train.csv\")\n",
    "val_df = pd.read_csv(os.getcwd() + \"/Split_Tanker_Bulk_Container_frugal_vv/validation.csv\")\n",
    "test_df = pd.read_csv(os.getcwd() + \"/Split_Tanker_Bulk_Container_frugal_vv/test.csv\")\n",
    "\n",
    "image_path = '../OpenSARShip/Categories/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_pairs(dataframe):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    categories = dataframe['file_path'].apply(lambda x: x.split('\\\\')[0]).unique()\n",
    "    \n",
    "    # Generate all unique combinations within the same class for similar pairs\n",
    "    for category in categories:\n",
    "        same_class_images = dataframe[dataframe['file_path'].str.contains(category, regex=False)]['file_path'].tolist()\n",
    "        for pair in combinations(same_class_images, 2):\n",
    "            pairs.append(pair)\n",
    "            labels.append(1)  # Similar pair\n",
    "    \n",
    "    # Generate all unique combinations across different classes for dissimilar pairs\n",
    "    for cat1, cat2 in combinations(categories, 2):\n",
    "        cat1_images = dataframe[dataframe['file_path'].str.contains(cat1, regex=False)]['file_path'].tolist()\n",
    "        cat2_images = dataframe[dataframe['file_path'].str.contains(cat2, regex=False)]['file_path'].tolist()\n",
    "        \n",
    "        for pair in product(cat1_images, cat2_images):\n",
    "            pairs.append(pair)\n",
    "            labels.append(0)  # Dissimilar pair\n",
    "    \n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pairs_to_csv(pairs, labels, csv_path):\n",
    "    df = pd.DataFrame({'image_1': pairs[:, 0], 'image_2': pairs[:, 1], 'label': labels})\n",
    "    # Shuffle the DataFrame\n",
    "    shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
    "    # Save the shuffled DataFrame to a CSV file\n",
    "    shuffled_df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    pairs = df[['image_1', 'image_2']].values\n",
    "    labels = df['label'].values\n",
    "    return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           file_path\n",
      "0  Bulk Carrier\\BulkCarrier_Visual_Cargo_x1902_y8...\n",
      "1  Bulk Carrier\\BulkCarrier_Visual_Cargo_x5067_y1...\n",
      "2  Bulk Carrier\\BulkCarrier_Visual_Cargo_x2412_y9...\n",
      "3  Bulk Carrier\\BulkCarrier_Visual_Cargo_x2084_y6...\n",
      "4  Container Ship\\ContainerShip_Visual_Cargo_x114...\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs, train_labels = generate_all_pairs(train_df)\n",
    "val_pairs, val_labels = generate_all_pairs(val_df)\n",
    "test_pairs, test_labels = generate_all_pairs(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pairs_to_csv(train_pairs, train_labels, 'train_pairs.csv')\n",
    "save_pairs_to_csv(val_pairs, val_labels, 'val_pairs.csv')\n",
    "save_pairs_to_csv(test_pairs, test_labels, 'test_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pairs of 1/4 of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrating pairs of images for 1/4 of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_pairs(dataframe, csv_path):\n",
    "    # Sample a quarter of the DataFrame\n",
    "    sampled_df = dataframe.sample(frac=0.25, random_state=42)  # Use a fixed seed for reproducibility\n",
    "\n",
    "    # Generate all pairs from the sampled DataFrame\n",
    "    pairs, labels = generate_all_pairs(sampled_df)\n",
    "    \n",
    "    # Save the pairs to a CSV file\n",
    "    save_pairs_to_csv(pairs, labels, csv_path)\n",
    "\n",
    "# Paths to your CSV files\n",
    "train_csv_path = os.getcwd() + \"/Split_Tanker_Bulk_Container_frugal_vv/train.csv\"\n",
    "val_csv_path = os.getcwd() + \"/Split_Tanker_Bulk_Container_frugal_vv/validation.csv\"\n",
    "test_csv_path = os.getcwd() + \"/Split_Tanker_Bulk_Container_frugal_vv/test.csv\"\n",
    "\n",
    "# Load the original DataFrames\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Generate and save pairs for each subset\n",
    "generate_and_save_pairs(train_df, 'train_pairs.csv')\n",
    "generate_and_save_pairs(val_df, 'val_pairs.csv')\n",
    "generate_and_save_pairs(test_df, 'test_pairs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split mstar in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import combinations, product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_pairs(data_root):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    categories = os.listdir(data_root)\n",
    "\n",
    "    # Generate pairs\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_root, category)\n",
    "        images = [os.path.join(category_path, img) for img in os.listdir(category_path)]\n",
    "        for pair in combinations(images, 2):\n",
    "            pairs.append(pair)\n",
    "            labels.append(1)  # Similar pair\n",
    "\n",
    "    for cat1, cat2 in combinations(categories, 2):\n",
    "        cat1_path = os.path.join(data_root, cat1)\n",
    "        cat2_path = os.path.join(data_root, cat2)\n",
    "        cat1_images = [os.path.join(cat1_path, img) for img in os.listdir(cat1_path)]\n",
    "        cat2_images = [os.path.join(cat2_path, img) for img in os.listdir(cat2_path)]\n",
    "        for pair in product(cat1_images, cat2_images):\n",
    "            pairs.append(pair)\n",
    "            labels.append(0)  # Dissimilar pair\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def save_pairs_to_csv(pairs, labels, csv_filename):\n",
    "    df = pd.DataFrame({'image_1': pairs[:, 0], 'image_2': pairs[:, 1], 'label': labels})\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "def split_dataset(pairs, labels, split_ratio=0.5):\n",
    "    # Shuffle and split the dataset\n",
    "    indices = np.arange(pairs.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    pairs = pairs[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    split_point = int(pairs.shape[0] * split_ratio)\n",
    "    return (pairs[split_point:], labels[split_point:], pairs[:split_point], labels[:split_point])\n",
    "\n",
    "# Generate pairs for the train dataset\n",
    "train_pairs, train_labels = generate_pairs('../mstar/TRAIN')\n",
    "save_pairs_to_csv(train_pairs, train_labels, 'train_pairs.csv')\n",
    "\n",
    "# Generate pairs for the test dataset and split into validation and test\n",
    "test_pairs, test_labels = generate_pairs('../mstar/TEST')\n",
    "test_pairs, test_labels, validation_pairs, validation_labels = split_dataset(test_pairs, test_labels, split_ratio=0.5)\n",
    "save_pairs_to_csv(test_pairs, test_labels, 'test_pairs.csv')\n",
    "save_pairs_to_csv(validation_pairs, validation_labels, 'validation_pairs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_quarter_to_csv(pairs, labels, csv_filename):\n",
    "    # Calculate the quarter point of the dataset\n",
    "    quarter_point = len(pairs) // 4\n",
    "    # Shuffle the dataset\n",
    "    shuffled_indices = np.random.permutation(len(pairs))\n",
    "    # Select a quarter of the data\n",
    "    selected_indices = shuffled_indices[:quarter_point]\n",
    "    # Create a DataFrame with the selected data\n",
    "    df = pd.DataFrame({\n",
    "        'image_1': pairs[selected_indices, 0],\n",
    "        'image_2': pairs[selected_indices, 1],\n",
    "        'label': labels[selected_indices]\n",
    "    })\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Assuming generate_pairs and other necessary functions are defined as before\n",
    "\n",
    "# Generate pairs for the train dataset and save a quarter\n",
    "train_pairs, train_labels = generate_pairs('../mstar/TRAIN')\n",
    "save_quarter_to_csv(train_pairs, train_labels, 'train_pairs_quarter.csv')\n",
    "\n",
    "# Generate pairs for the test dataset\n",
    "test_pairs, test_labels = generate_pairs('../mstar/TEST')\n",
    "# Split into validation and test, then save a quarter of each\n",
    "test_pairs, test_labels, validation_pairs, validation_labels = split_dataset(test_pairs, test_labels, split_ratio=0.5)\n",
    "save_quarter_to_csv(test_pairs, test_labels, 'test_pairs_quarter.csv')\n",
    "save_quarter_to_csv(validation_pairs, validation_labels, 'validation_pairs_quarter.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
